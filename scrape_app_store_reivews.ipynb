{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz4KcE028p6B"
   },
   "source": [
    "# **Scrape Apple App Store Reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests pandas tqdm numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3029,
     "status": "ok",
     "timestamp": 1684652409266,
     "user": {
      "displayName": "Glenn Fang",
      "userId": "06064883442212685341"
     },
     "user_tz": -480
    },
    "id": "E3nkY6Hl10hE",
    "outputId": "c31158ce-6f41-43c7-eeec-6b4548b9251b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "print(f\"requests=={requests.__version__}\")\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install app-store-web-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app_store_web_scraper import AppStoreSession, AppStoreEntry\n",
    "\n",
    "country_codes = ['us', 'in', 'gb', 'ca', 'au', 'ae', 'de', 'fr', 'it', 'sg']\n",
    "all_reviews = []\n",
    "for i in country_codes:\n",
    "    try:\n",
    "        session = AppStoreSession()\n",
    "    \n",
    "        entry = AppStoreEntry(\"726070762\", country=i, session=session) #update your app ID here\n",
    "        reviews = list(entry.reviews())\n",
    "        for r in reviews:\n",
    "            if hasattr(r, \"__dict__\"):\n",
    "                rd = r.__dict__.copy()\n",
    "            else:\n",
    "                rd = dict(r._asdict())\n",
    "            rd['country'] = i\n",
    "            all_reviews.append(rd)\n",
    "        print(f\"Fetched {len(reviews)} from {i}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for country: {i} => {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From extracted reviews removing Customer Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_reviews = [\n",
    "    {k: v for k, v in review.items() if k not in ['user_name', 'id']}\n",
    "    for review in all_reviews\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting it into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "reviews_data = []\n",
    "for review in filtered_reviews :\n",
    "    reviews_data.append({\n",
    "        'content': review.get('content', ''),\n",
    "        'score': review.get('rating', 0),\n",
    "        'at': review.get('date', datetime.now()),\n",
    "        'title': review.get('title', ''),\n",
    "        'reviewCreatedVersion': review.get('app_version', ''),\n",
    "        'Country':review.get('country',''),\n",
    "        'replyContent': None,\n",
    "        'repliedAt': None\n",
    "    })\n",
    "\n",
    "reviews_df = pd.DataFrame(reviews_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv('Appstore_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall numpy scipy -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "def _categorize_rating(score):\n",
    "    \"\"\"Categorize rating into groups\"\"\"\n",
    "    if score >= 4:\n",
    "        return 'Positive'\n",
    "    elif score >= 3:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "def _clean_text(text):\n",
    "    \"\"\"Clean text for analysis\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,!?-]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_reviews():\n",
    "    \"\"\"Minimal preprocessing optimized for LLM analysis\"\"\"\n",
    "    print(\"AppStoreEntryPreprocessing reviews...\")\n",
    "\n",
    "    if reviews_df is None or reviews_df.empty:\n",
    "        print(\"No reviews to preprocess\")\n",
    "        return\n",
    "\n",
    "    processed_df = reviews_df.copy()\n",
    "    processed_df['content_clean'] = processed_df['content'].apply(_clean_text)\n",
    "    processed_df['review_length'] = processed_df['content'].str.len()\n",
    "    processed_df['word_count'] = processed_df['content'].str.split().str.len()\n",
    "    processed_df['sentence_count'] = processed_df['content'].apply(lambda x: len(sent_tokenize(x)))\n",
    "    processed_df['review_date'] = pd.to_datetime(processed_df['at'])\n",
    "    processed_df['year'] = processed_df['review_date'].dt.year\n",
    "    processed_df['month'] = processed_df['review_date'].dt.month\n",
    "    processed_df['day_of_week'] = processed_df['review_date'].dt.day_name()\n",
    "    processed_df['rating_category'] = processed_df['score'].apply(_categorize_rating)\n",
    "    print(f\"âœ“ Preprocessed {len(processed_df)} reviews\")\n",
    "    return processed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_reviews()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNkEmtd4h3rnoxIM7m3DWHr",
   "mount_file_id": "1t19r-IrOWzYo4Xu9yilTgohvUSCRjlJS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.11.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
